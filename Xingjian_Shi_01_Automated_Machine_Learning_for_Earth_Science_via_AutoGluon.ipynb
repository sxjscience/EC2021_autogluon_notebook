{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning for Earth Science via AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author1 = {\"name\": \"Xingjian Shi\", \"affiliation\": \"Amazon Web Services\", \"email\": \"xjshi@amazon.com\", \"orcid\": \"\"}\n",
    "- Author2 = {\"name\": \"Wen-ming Ye\", \"affiliation\": \"Amazon Web Services\", \"email\": \"wye@amazon.com\", \"orcid\": \"\"}\n",
    "- Author3 = {\"name\": \"Nick Erickson\", \"affiliation\": \"Amazon Web Services\", \"email\": \"neerick@amazon.com\", \"orcid\": \"\"}\n",
    "- Author4 = {\"name\": \"Jonas Mueller\", \"affiliation\": \"Amazon Web Services\", \"email\": \"jonasmue@amazon.com\", \"orcid\": \"\"}\n",
    "- Author5 = {\"name\": \"Alexander Shirkov\", \"affiliation\": \"Amazon Web Services\", \"email\": \"ashyrkou@amazon.com\", \"orcid\": \"\"}\n",
    "- Author6 = {\"name\": \"Zhi Zhang\", \"affiliation\": \"Amazon Web Services\", \"email\": \"zhiz@amazon.com\", \"orcid\": \"\"}\n",
    "- Author7 = {\"name\": \"Mu Li\", \"affiliation\": \"Amazon Web Services\", \"email\": \"mli@amazon.com\", \"orcid\": \"\"}\n",
    "- Author8 = {\"name\": \"Alexander Smola\", \"affiliation\": \"Amazon Web Services\", \"email\": \"alex@smola.org\", \"orcid\": \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Purpose](#purpose)\n",
    "* [Setup](#setup)\n",
    "* [Forest Cover Type Classification](#forest-cover-type-classification)\n",
    "    * [Train Model with One Line](#train-model-with-one-line)\n",
    "    * [Evaluation and Prediction](#evaluation-and-prediction)\n",
    "    * [Load the Predictor](#load-the-predictor)\n",
    "    * [Feature Importance](#feature-importance)\n",
    "    * [Achieve Better Performance](#achieve-better-performance)\n",
    "* [Solar Radiation Prediction](#solar-radiation-predictions)\n",
    "* [More Information](#more-information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce [AutoGluon](https://github.com/awslabs/autogluon) to the Earth science community. AutoGluon is an automated machine learning toolkit that enables users to solve machine learning problems with a single line of code. Many earth science problems involve tabular-like datasets. With AutoGluon, you can feed in the **raw** data table and specify the `label` column. AutoGluon will deliver a model that has reasonable performance in a short period of time. In addition, with AutoGluon, you can also analyze the importance of each feature column with a single line of code. In the following, we illustrate how to use AutoGluon to build machine learning models for two Earth Science problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We will install [AutoGluon](https://github.com/awslabs/autogluon) via pip and also fix the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install autogluon --quiet\n",
    "!python3 -m pip install mxnet --quiet\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Cover Type Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first example, we will predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables. The dataset is downloaded from [Kaggle Forest Cover Type Prediction](https://www.kaggle.com/c/forest-cover-type-prediction). Study area of the dataset includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type. Let's first download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-14 04:10:03--  https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/forest-cover-type-prediction.zip\n",
      "Resolving deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)... 52.217.110.204\n",
      "Connecting to deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)|52.217.110.204|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26555059 (25M) [application/zip]\n",
      "Saving to: ‘forest-cover-type-prediction.zip’\n",
      "\n",
      "forest-cover-type-p 100%[===================>]  25.32M  56.1MB/s    in 0.5s    \n",
      "\n",
      "2021-04-14 04:10:04 (56.1 MB/s) - ‘forest-cover-type-prediction.zip’ saved [26555059/26555059]\n",
      "\n",
      "Archive:  forest-cover-type-prediction.zip\n",
      "  inflating: forest-cover-type-prediction/sampleSubmission.csv  \n",
      "  inflating: forest-cover-type-prediction/sampleSubmission.csv.zip  \n",
      "  inflating: forest-cover-type-prediction/test.csv  \n",
      "  inflating: forest-cover-type-prediction/test.csv.zip  \n",
      "  inflating: forest-cover-type-prediction/test3.csv  \n",
      "  inflating: forest-cover-type-prediction/train.csv  \n",
      "  inflating: forest-cover-type-prediction/train.csv.zip  \n"
     ]
    }
   ],
   "source": [
    "!wget https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/forest-cover-type-prediction.zip -O forest-cover-type-prediction.zip\n",
    "!unzip -o forest-cover-type-prediction.zip -d forest-cover-type-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load and visualize the dataset. We will split the dataset to 80% training and 20% development for the purpose of reporting the score on the development data. Also, for the purpose of demonstration, we will subsample the dataset to 5000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('forest-cover-type-prediction/train.csv.zip')\n",
    "df = df.drop('Id', 1)\n",
    "df = df.sample(5000, random_state=100)\n",
    "train_df, dev_df = train_test_split(df, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visualizing the dataset, we can see that there are 54 feature columns and 1 label column called `\"Cover_Type\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>2762</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>270</td>\n",
       "      <td>49</td>\n",
       "      <td>2639</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>134</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13086</th>\n",
       "      <td>2283</td>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "      <td>240</td>\n",
       "      <td>227</td>\n",
       "      <td>116</td>\n",
       "      <td>1187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14221</th>\n",
       "      <td>3220</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>247</td>\n",
       "      <td>66</td>\n",
       "      <td>3328</td>\n",
       "      <td>239</td>\n",
       "      <td>214</td>\n",
       "      <td>103</td>\n",
       "      <td>819</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>3021</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>201</td>\n",
       "      <td>26</td>\n",
       "      <td>4134</td>\n",
       "      <td>228</td>\n",
       "      <td>225</td>\n",
       "      <td>130</td>\n",
       "      <td>2493</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>2446</td>\n",
       "      <td>76</td>\n",
       "      <td>21</td>\n",
       "      <td>469</td>\n",
       "      <td>105</td>\n",
       "      <td>726</td>\n",
       "      <td>241</td>\n",
       "      <td>196</td>\n",
       "      <td>75</td>\n",
       "      <td>1401</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "7449        2762      17     16                               270   \n",
       "13086       2283     109     11                                 0   \n",
       "14221       3220      82     14                               247   \n",
       "768         3021      68      8                               201   \n",
       "6132        2446      76     21                               469   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "7449                               49                             2639   \n",
       "13086                               0                             1138   \n",
       "14221                              66                             3328   \n",
       "768                                26                             4134   \n",
       "6132                              105                              726   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "7449             206             206            134   \n",
       "13086            240             227            116   \n",
       "14221            239             214            103   \n",
       "768              228             225            130   \n",
       "6132             241             196             75   \n",
       "\n",
       "       Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "7449                                  268  ...            0            0   \n",
       "13086                                1187  ...            0            0   \n",
       "14221                                 819  ...            1            0   \n",
       "768                                  2493  ...            0            0   \n",
       "6132                                 1401  ...            0            0   \n",
       "\n",
       "       Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "7449             0            0            0            0            0   \n",
       "13086            0            0            0            0            0   \n",
       "14221            0            0            0            0            0   \n",
       "768              0            0            0            0            0   \n",
       "6132             0            0            0            0            0   \n",
       "\n",
       "       Soil_Type39  Soil_Type40  Cover_Type  \n",
       "7449             0            0           5  \n",
       "13086            0            0           4  \n",
       "14221            0            0           1  \n",
       "768              0            0           1  \n",
       "6132             0            0           6  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model with One Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a model in AutoGluon with a single line of code. We will just need to specify the label column before calling `.fit()`. Here, the label column is `Cover_Type`. AutoGluno will inference the problem type automatically. In our example, it can correctly figure out that it is a \"multiclass\" classification problem and output the model with the best accuracy. Internally, it will also figure out the feature type automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_ec2021_demo\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"ag_ec2021_demo/\"\n",
      "AutoGluon Version:  0.1.0\n",
      "Train Data Rows:    3750\n",
      "Train Data Columns: 54\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t7 unique label values:  [5, 4, 1, 6, 3, 2, 7]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "NumExpr defaulting to 8 threads.\n",
      "Train Data Class Count: 7\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    32024.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.62 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['Soil_Type7', 'Soil_Type8', 'Soil_Type15', 'Soil_Type25']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 50 | ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 50 | ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t50 features in original data used to generate 50 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.5 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.13333333333333333, Train Rows: 3250, Val Rows: 500\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t0.798\t = Validation accuracy score\n",
      "\t9.97s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.802\t = Validation accuracy score\n",
      "\t22.74s\t = Training runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.72\t = Validation accuracy score\n",
      "\t0.02s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.744\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.822\t = Validation accuracy score\n",
      "\t0.82s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.824\t = Validation accuracy score\n",
      "\t1.03s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.802\t = Validation accuracy score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.804\t = Validation accuracy score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.832\t = Validation accuracy score\n",
      "\t3.4s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t1.97s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.812\t = Validation accuracy score\n",
      "\t4.77s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.816\t = Validation accuracy score\n",
      "\t6.68s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.834\t = Validation accuracy score\n",
      "\t7.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.854\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 65.82s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_ec2021_demo/\")\n"
     ]
    }
   ],
   "source": [
    "import autogluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label='Cover_Type', path='ag_ec2021_demo').fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the performance of each model with `predictor.leaderboard()`. Internally, AutoGluon trains a diverse set of different tabular models and computes a weighted ensemble to combine these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2      0.854       1.054986  43.385918                0.000447           0.353042            2       True         14\n",
      "1         LightGBMLarge      0.834       0.020090   7.005562                0.020090           7.005562            1       True         13\n",
      "2              LightGBM      0.832       0.040622   3.404332                0.040622           3.404332            1       True          9\n",
      "3            LightGBMXT      0.830       0.028808   1.973339                0.028808           1.973339            1       True         10\n",
      "4      RandomForestEntr      0.824       0.102591   1.027688                0.102591           1.027688            1       True          6\n",
      "5      RandomForestGini      0.822       0.102530   0.824320                0.102530           0.824320            1       True          5\n",
      "6               XGBoost      0.816       0.010418   6.679732                0.010418           6.679732            1       True         12\n",
      "7              CatBoost      0.812       0.003853   4.765288                0.003853           4.765288            1       True         11\n",
      "8        ExtraTreesEntr      0.804       0.102545   0.718240                0.102545           0.718240            1       True          8\n",
      "9        ExtraTreesGini      0.802       0.102536   0.716514                0.102536           0.716514            1       True          7\n",
      "10      NeuralNetFastAI      0.802       0.311262  22.742396                0.311262          22.742396            1       True          2\n",
      "11       NeuralNetMXNet      0.798       0.106743   9.969723                0.106743           9.969723            1       True          1\n",
      "12       KNeighborsDist      0.744       0.102503   0.013335                0.102503           0.013335            1       True          4\n",
      "13       KNeighborsUnif      0.720       0.103739   0.015097                0.103739           0.015097            1       True          3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.854</td>\n",
       "      <td>1.054986</td>\n",
       "      <td>43.385918</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.353042</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>7.005562</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>7.005562</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.040622</td>\n",
       "      <td>3.404332</td>\n",
       "      <td>0.040622</td>\n",
       "      <td>3.404332</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.028808</td>\n",
       "      <td>1.973339</td>\n",
       "      <td>0.028808</td>\n",
       "      <td>1.973339</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.102591</td>\n",
       "      <td>1.027688</td>\n",
       "      <td>0.102591</td>\n",
       "      <td>1.027688</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>0.824320</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>0.824320</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>6.679732</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>6.679732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>4.765288</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>4.765288</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.102545</td>\n",
       "      <td>0.718240</td>\n",
       "      <td>0.102545</td>\n",
       "      <td>0.718240</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.102536</td>\n",
       "      <td>0.716514</td>\n",
       "      <td>0.102536</td>\n",
       "      <td>0.716514</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.311262</td>\n",
       "      <td>22.742396</td>\n",
       "      <td>0.311262</td>\n",
       "      <td>22.742396</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetMXNet</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>9.969723</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>9.969723</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.102503</td>\n",
       "      <td>0.013335</td>\n",
       "      <td>0.102503</td>\n",
       "      <td>0.013335</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.103739</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.103739</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2      0.854       1.054986  43.385918   \n",
       "1         LightGBMLarge      0.834       0.020090   7.005562   \n",
       "2              LightGBM      0.832       0.040622   3.404332   \n",
       "3            LightGBMXT      0.830       0.028808   1.973339   \n",
       "4      RandomForestEntr      0.824       0.102591   1.027688   \n",
       "5      RandomForestGini      0.822       0.102530   0.824320   \n",
       "6               XGBoost      0.816       0.010418   6.679732   \n",
       "7              CatBoost      0.812       0.003853   4.765288   \n",
       "8        ExtraTreesEntr      0.804       0.102545   0.718240   \n",
       "9        ExtraTreesGini      0.802       0.102536   0.716514   \n",
       "10      NeuralNetFastAI      0.802       0.311262  22.742396   \n",
       "11       NeuralNetMXNet      0.798       0.106743   9.969723   \n",
       "12       KNeighborsDist      0.744       0.102503   0.013335   \n",
       "13       KNeighborsUnif      0.720       0.103739   0.015097   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000447           0.353042            2       True   \n",
       "1                 0.020090           7.005562            1       True   \n",
       "2                 0.040622           3.404332            1       True   \n",
       "3                 0.028808           1.973339            1       True   \n",
       "4                 0.102591           1.027688            1       True   \n",
       "5                 0.102530           0.824320            1       True   \n",
       "6                 0.010418           6.679732            1       True   \n",
       "7                 0.003853           4.765288            1       True   \n",
       "8                 0.102545           0.718240            1       True   \n",
       "9                 0.102536           0.716514            1       True   \n",
       "10                0.311262          22.742396            1       True   \n",
       "11                0.106743           9.969723            1       True   \n",
       "12                0.102503           0.013335            1       True   \n",
       "13                0.103739           0.015097            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1          13  \n",
       "2           9  \n",
       "3          10  \n",
       "4           6  \n",
       "5           5  \n",
       "6          12  \n",
       "7          11  \n",
       "8           8  \n",
       "9           7  \n",
       "10          2  \n",
       "11          1  \n",
       "12          4  \n",
       "13          3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the model performance on the heldout predictor dataset by calling `.evaluate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive performance on given data: accuracy = 0.8184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8184"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the prediction, you may just use  `predictor.predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6084     3\n",
       "927      5\n",
       "10919    3\n",
       "8867     2\n",
       "14455    7\n",
       "        ..\n",
       "6618     5\n",
       "9591     7\n",
       "14307    1\n",
       "1553     1\n",
       "3        2\n",
       "Name: Cover_Type, Length: 1250, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictor.predict(dev_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problems, we can also use `.predict_proba` to get the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.619037</td>\n",
       "      <td>0.332179</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.046162</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.096049</td>\n",
       "      <td>0.418703</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.459582</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10919</th>\n",
       "      <td>0.023226</td>\n",
       "      <td>0.093982</td>\n",
       "      <td>0.643261</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.156072</td>\n",
       "      <td>0.079185</td>\n",
       "      <td>0.003726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8867</th>\n",
       "      <td>0.263310</td>\n",
       "      <td>0.569940</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.139799</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14455</th>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.991459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7\n",
       "6084   0.000142  0.001430  0.619037  0.332179  0.000683  0.046162  0.000368\n",
       "927    0.096049  0.418703  0.004163  0.002901  0.459582  0.008953  0.009649\n",
       "10919  0.023226  0.093982  0.643261  0.000548  0.156072  0.079185  0.003726\n",
       "8867   0.263310  0.569940  0.009541  0.000104  0.139799  0.002734  0.014572\n",
       "14455  0.004969  0.003474  0.000023  0.000017  0.000043  0.000016  0.991459"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = predictor.predict_proba(dev_df)\n",
    "probs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a AutoGluon model is straight-forward. We can directly call `.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive performance on given data: accuracy = 0.8184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8184"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_loaded = TabularPredictor.load('ag_ec2021_demo')\n",
    "predictor_loaded.evaluate(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon offers a built-in method for calculating the relative importance of each feature based on [permutation-shuffling](https://scikit-learn.org/stable/modules/permutation_importance.html). In the following, we calculate the feature importance and print the top-10 important features. Here, `importance` means the importance score and the other values give you an understanding of the statistical significance of the calculated score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 54 features using 1000 rows with 3 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t308.54s\t= Expected runtime (102.85s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t40.87s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.403000</td>\n",
       "      <td>0.024576</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>3</td>\n",
       "      <td>0.543826</td>\n",
       "      <td>0.262174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>3</td>\n",
       "      <td>0.129954</td>\n",
       "      <td>0.030046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.059333</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>3</td>\n",
       "      <td>0.123739</td>\n",
       "      <td>-0.005072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>3</td>\n",
       "      <td>0.077413</td>\n",
       "      <td>0.023254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035460</td>\n",
       "      <td>0.012540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>3</td>\n",
       "      <td>0.045133</td>\n",
       "      <td>-0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>0.070509</td>\n",
       "      <td>3</td>\n",
       "      <td>0.091568</td>\n",
       "      <td>-0.056235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.068788</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059722</td>\n",
       "      <td>-0.036389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type4</th>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>-0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance    stddev   p_value  n  \\\n",
       "Elevation                             0.403000  0.024576  0.000619  3   \n",
       "Horizontal_Distance_To_Roadways       0.080000  0.008718  0.001967  3   \n",
       "Horizontal_Distance_To_Fire_Points    0.059333  0.011240  0.005876  3   \n",
       "Horizontal_Distance_To_Hydrology      0.050333  0.004726  0.001463  3   \n",
       "Wilderness_Area4                      0.024000  0.002000  0.001153  3   \n",
       "Wilderness_Area3                      0.018667  0.004619  0.009902  3   \n",
       "Hillshade_Noon                        0.017667  0.012897  0.070509  3   \n",
       "Vertical_Distance_To_Hydrology        0.011667  0.008386  0.068788  3   \n",
       "Soil_Type4                            0.011000  0.001732  0.004082  3   \n",
       "Slope                                 0.008667  0.001528  0.005098  3   \n",
       "\n",
       "                                    p99_high   p99_low  \n",
       "Elevation                           0.543826  0.262174  \n",
       "Horizontal_Distance_To_Roadways     0.129954  0.030046  \n",
       "Horizontal_Distance_To_Fire_Points  0.123739 -0.005072  \n",
       "Horizontal_Distance_To_Hydrology    0.077413  0.023254  \n",
       "Wilderness_Area4                    0.035460  0.012540  \n",
       "Wilderness_Area3                    0.045133 -0.007800  \n",
       "Hillshade_Noon                      0.091568 -0.056235  \n",
       "Vertical_Distance_To_Hydrology      0.059722 -0.036389  \n",
       "Soil_Type4                          0.020925  0.001075  \n",
       "Slope                               0.017420 -0.000086  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = predictor.feature_importance(dev_df)\n",
    "importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, we can see that `Elevation` is the most important feature. `Horizontal_Distance_To_Roadways` is the 2nd most important feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achieve Better Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default behavior of AutoGluon is to compute a weighted ensemble of a diverse set of models. Usually, you can achieve better performance via stack ensembling. To achieve better performance based on automated stack ensembling, you can specify `presets=\"best_quality\"` when calling `.fit()` in AutoGluon. For more details, you can also checkout our provided script. The detailed architecture is described in [1] and we also provide the following figure so you can know the general architecture.\n",
    "\n",
    "<img src=\"https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/stacking.png\" alt=\"screenshot\" style=\"width: 500px;\"/>\n",
    "\n",
    "With `.fit(train_df, presets=\"best_quality\")`, we are able to achieve 82/1692 in the competition. To reproduce our number, you may try the command mentioned in [link](https://github.com/sxjscience/EC2021_autogluon_notebook).\n",
    "\n",
    "<img src=\"https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/forest_cover_type.png\" alt=\"screenshot\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Radiation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second example, we will train model to predict the solar radiation. The orignal dataset is available in [Kaggle Solar Radiation Prediction](https://www.kaggle.com/dronio/SolarEnergy). The dataset contains such columns as: \"wind direction\", \"wind speed\", \"humidity\" and \"temperature\". The response parameter that is to be predicted is: \"Solar_radiation\". It contains measurements for the past 4 months and you have to predict the level of solar radiation. Let's download and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-14 04:12:01--  https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/SolarPrediction.csv.zip\n",
      "Resolving deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)... 52.217.39.180\n",
      "Connecting to deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)|52.217.39.180|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 523425 (511K) [application/zip]\n",
      "Saving to: ‘SolarPrediction.csv.zip’\n",
      "\n",
      "SolarPrediction.csv 100%[===================>] 511.16K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2021-04-14 04:12:01 (74.1 MB/s) - ‘SolarPrediction.csv.zip’ saved [523425/523425]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/SolarPrediction.csv.zip -O SolarPrediction.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('SolarPrediction.csv.zip')\n",
    "train_df, dev_df = train_test_split(df, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIXTime</th>\n",
       "      <th>Data</th>\n",
       "      <th>Time</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindDirection(Degrees)</th>\n",
       "      <th>Speed</th>\n",
       "      <th>TimeSunRise</th>\n",
       "      <th>TimeSunSet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>1474412104</td>\n",
       "      <td>9/20/2016 12:00:00 AM</td>\n",
       "      <td>12:55:04</td>\n",
       "      <td>1039.15</td>\n",
       "      <td>65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>57</td>\n",
       "      <td>2.26</td>\n",
       "      <td>5.62</td>\n",
       "      <td>06:11:00</td>\n",
       "      <td>18:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12230</th>\n",
       "      <td>1476543319</td>\n",
       "      <td>10/15/2016 12:00:00 AM</td>\n",
       "      <td>04:55:19</td>\n",
       "      <td>1.21</td>\n",
       "      <td>51</td>\n",
       "      <td>30.46</td>\n",
       "      <td>23</td>\n",
       "      <td>181.58</td>\n",
       "      <td>6.75</td>\n",
       "      <td>06:17:00</td>\n",
       "      <td>17:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11706</th>\n",
       "      <td>1476704422</td>\n",
       "      <td>10/17/2016 12:00:00 AM</td>\n",
       "      <td>01:40:22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>50</td>\n",
       "      <td>30.47</td>\n",
       "      <td>39</td>\n",
       "      <td>142.56</td>\n",
       "      <td>10.12</td>\n",
       "      <td>06:18:00</td>\n",
       "      <td>17:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924</th>\n",
       "      <td>1476330025</td>\n",
       "      <td>10/12/2016 12:00:00 AM</td>\n",
       "      <td>17:40:25</td>\n",
       "      <td>28.35</td>\n",
       "      <td>59</td>\n",
       "      <td>30.45</td>\n",
       "      <td>42</td>\n",
       "      <td>167.42</td>\n",
       "      <td>4.50</td>\n",
       "      <td>06:16:00</td>\n",
       "      <td>18:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27507</th>\n",
       "      <td>1482367563</td>\n",
       "      <td>12/21/2016 12:00:00 AM</td>\n",
       "      <td>14:46:03</td>\n",
       "      <td>637.93</td>\n",
       "      <td>57</td>\n",
       "      <td>30.39</td>\n",
       "      <td>74</td>\n",
       "      <td>40.94</td>\n",
       "      <td>4.50</td>\n",
       "      <td>06:53:00</td>\n",
       "      <td>17:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>1474457405</td>\n",
       "      <td>9/21/2016 12:00:00 AM</td>\n",
       "      <td>01:30:05</td>\n",
       "      <td>1.21</td>\n",
       "      <td>45</td>\n",
       "      <td>30.39</td>\n",
       "      <td>73</td>\n",
       "      <td>159.07</td>\n",
       "      <td>3.37</td>\n",
       "      <td>06:11:00</td>\n",
       "      <td>18:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32227</th>\n",
       "      <td>1480723808</td>\n",
       "      <td>12/2/2016 12:00:00 AM</td>\n",
       "      <td>14:10:08</td>\n",
       "      <td>177.19</td>\n",
       "      <td>45</td>\n",
       "      <td>30.34</td>\n",
       "      <td>93</td>\n",
       "      <td>134.78</td>\n",
       "      <td>11.25</td>\n",
       "      <td>06:42:00</td>\n",
       "      <td>17:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12705</th>\n",
       "      <td>1476396922</td>\n",
       "      <td>10/13/2016 12:00:00 AM</td>\n",
       "      <td>12:15:22</td>\n",
       "      <td>1008.08</td>\n",
       "      <td>65</td>\n",
       "      <td>30.46</td>\n",
       "      <td>46</td>\n",
       "      <td>71.24</td>\n",
       "      <td>5.62</td>\n",
       "      <td>06:17:00</td>\n",
       "      <td>18:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>1475697322</td>\n",
       "      <td>10/5/2016 12:00:00 AM</td>\n",
       "      <td>09:55:22</td>\n",
       "      <td>292.44</td>\n",
       "      <td>55</td>\n",
       "      <td>30.47</td>\n",
       "      <td>101</td>\n",
       "      <td>18.70</td>\n",
       "      <td>7.87</td>\n",
       "      <td>06:14:00</td>\n",
       "      <td>18:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23615</th>\n",
       "      <td>1478267417</td>\n",
       "      <td>11/4/2016 12:00:00 AM</td>\n",
       "      <td>03:50:17</td>\n",
       "      <td>1.18</td>\n",
       "      <td>44</td>\n",
       "      <td>30.42</td>\n",
       "      <td>38</td>\n",
       "      <td>176.34</td>\n",
       "      <td>7.87</td>\n",
       "      <td>06:25:00</td>\n",
       "      <td>17:47:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UNIXTime                    Data      Time  Radiation  Temperature  \\\n",
       "2664   1474412104   9/20/2016 12:00:00 AM  12:55:04    1039.15           65   \n",
       "12230  1476543319  10/15/2016 12:00:00 AM  04:55:19       1.21           51   \n",
       "11706  1476704422  10/17/2016 12:00:00 AM  01:40:22       1.22           50   \n",
       "12924  1476330025  10/12/2016 12:00:00 AM  17:40:25      28.35           59   \n",
       "27507  1482367563  12/21/2016 12:00:00 AM  14:46:03     637.93           57   \n",
       "2516   1474457405   9/21/2016 12:00:00 AM  01:30:05       1.21           45   \n",
       "32227  1480723808   12/2/2016 12:00:00 AM  14:10:08     177.19           45   \n",
       "12705  1476396922  10/13/2016 12:00:00 AM  12:15:22    1008.08           65   \n",
       "14992  1475697322   10/5/2016 12:00:00 AM  09:55:22     292.44           55   \n",
       "23615  1478267417   11/4/2016 12:00:00 AM  03:50:17       1.18           44   \n",
       "\n",
       "       Pressure  Humidity  WindDirection(Degrees)  Speed TimeSunRise  \\\n",
       "2664      30.40        57                    2.26   5.62    06:11:00   \n",
       "12230     30.46        23                  181.58   6.75    06:17:00   \n",
       "11706     30.47        39                  142.56  10.12    06:18:00   \n",
       "12924     30.45        42                  167.42   4.50    06:16:00   \n",
       "27507     30.39        74                   40.94   4.50    06:53:00   \n",
       "2516      30.39        73                  159.07   3.37    06:11:00   \n",
       "32227     30.34        93                  134.78  11.25    06:42:00   \n",
       "12705     30.46        46                   71.24   5.62    06:17:00   \n",
       "14992     30.47       101                   18.70   7.87    06:14:00   \n",
       "23615     30.42        38                  176.34   7.87    06:25:00   \n",
       "\n",
       "      TimeSunSet  \n",
       "2664    18:21:00  \n",
       "12230   17:59:00  \n",
       "11706   17:58:00  \n",
       "12924   18:02:00  \n",
       "27507   17:49:00  \n",
       "2516    18:20:00  \n",
       "32227   17:42:00  \n",
       "12705   18:01:00  \n",
       "14992   18:08:00  \n",
       "23615   17:47:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in our previos example, we can directly train a predictor with a single `.fit()` call. The difference is that AutoGluon can automatically determine that it is a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"ag_ec2021_demo2/\"\n",
      "AutoGluon Version:  0.1.0\n",
      "Train Data Rows:    24514\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1601.26, 1.11, 206.52072, 315.54334)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    28552.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.88 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 3 | ['Pressure', 'WindDirection(Degrees)', 'Speed']\n",
      "\t\t('int', [])                        : 3 | ['UNIXTime', 'Temperature', 'Humidity']\n",
      "\t\t('object', ['datetime_as_object']) : 4 | ['Data', 'Time', 'TimeSunRise', 'TimeSunSet']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['Pressure', 'WindDirection(Degrees)', 'Speed']\n",
      "\t\t('int', [])                  : 3 | ['UNIXTime', 'Temperature', 'Humidity']\n",
      "\t\t('int', ['datetime_as_int']) : 4 | ['Data', 'Time', 'TimeSunRise', 'TimeSunSet']\n",
      "\t17.2s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 17.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 22062, Val Rows: 2452\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t0.9437\t = Validation r2 score\n",
      "\t7.01s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t0.9473\t = Validation r2 score\n",
      "\t3.31s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.9501\t = Validation r2 score\n",
      "\t0.03s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.9531\t = Validation r2 score\n",
      "\t0.03s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9438\t = Validation r2 score\n",
      "\t2.17s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's l2: 5825\ttrain_set's r2: 0.941343\tvalid_set's l2: 6881.24\tvalid_set's r2: 0.932405\n",
      "[2000]\ttrain_set's l2: 4818.35\ttrain_set's r2: 0.951483\tvalid_set's l2: 6360.95\tvalid_set's r2: 0.937497\n",
      "[3000]\ttrain_set's l2: 4202.38\ttrain_set's r2: 0.957684\tvalid_set's l2: 6212.24\tvalid_set's r2: 0.938993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9393\t = Validation r2 score\n",
      "\t8.03s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9423\t = Validation r2 score\n",
      "\t5.65s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9431\t = Validation r2 score\n",
      "\t4.02s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t0.9378\t = Validation r2 score\n",
      "\t99.86s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/callbacks/tracker.py:50: UserWarning: <class 'autogluon.tabular.models.fastainn.callbacks.EarlyStoppingCallbackWithTimeLimit'> conditioned on metric `r2` which is not available. Available metrics are: train_loss, valid_loss, r2_score\n",
      "  warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {\", \".join(map(str, self.learn.recorder.names[1:-1]))}')\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/callbacks/tracker.py:50: UserWarning: <class 'autogluon.tabular.models.fastainn.callbacks.SaveModelCallback'> conditioned on metric `r2` which is not available. Available metrics are: train_loss, valid_loss, r2_score\n",
      "  warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {\", \".join(map(str, self.learn.recorder.names[1:-1]))}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\t[Errno 2] No such file or directory: '/tmp/tmp08gi6y8t/models/NeuralNetFastAI.pth'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 911, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 883, in _train_single\n",
      "    model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 405, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 244, in _fit\n",
      "    model.load(self.name)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/fastai/basic_train.py\", line 269, in load\n",
      "    state = torch.load(source, map_location=device)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/torch/serialization.py\", line 581, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp08gi6y8t/models/NeuralNetFastAI.pth'\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9445\t = Validation r2 score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9548\t = Validation r2 score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 219.66s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_ec2021_demo2/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='Radiation', eval_metric='r2', path='ag_ec2021_demo2').fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate on the development set by calling `.evaluate()`. Here, we have specified the model to use [R2 score](https://en.wikipedia.org/wiki/Coefficient_of_determination) so it will report the R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive performance on given data: r2 = 0.9544366398127356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9544366398127356"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can also measure the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 10 features using 1000 rows with 3 shuffle sets...\n",
      "\t31.34s\t= Expected runtime (10.45s per shuffle set)\n",
      "\t7.49s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UNIXTime</th>\n",
       "      <td>0.976487</td>\n",
       "      <td>0.038612</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>3</td>\n",
       "      <td>1.197739</td>\n",
       "      <td>0.755236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.095032</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>0.065370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <td>0.043758</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>3</td>\n",
       "      <td>0.062149</td>\n",
       "      <td>0.025368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>0.036498</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>3</td>\n",
       "      <td>0.054823</td>\n",
       "      <td>0.018173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeSunRise</th>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.058923</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030533</td>\n",
       "      <td>-0.017668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity</th>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeSunSet</th>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>-0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure</th>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.073446</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>-0.003375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speed</th>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.670472</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>-0.004195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindDirection(Degrees)</th>\n",
       "      <td>-0.000311</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.666522</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>-0.006499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        importance    stddev   p_value  n  p99_high   p99_low\n",
       "UNIXTime                  0.976487  0.038612  0.000260  3  1.197739  0.755236\n",
       "Time                      0.095032  0.005177  0.000494  3  0.124695  0.065370\n",
       "Data                      0.043758  0.003209  0.000894  3  0.062149  0.025368\n",
       "Temperature               0.036498  0.003198  0.001275  3  0.054823  0.018173\n",
       "TimeSunRise               0.006433  0.004206  0.058923  3  0.030533 -0.017668\n",
       "Humidity                  0.005896  0.000836  0.003315  3  0.010684  0.001108\n",
       "TimeSunSet                0.003256  0.000726  0.008082  3  0.007416 -0.000903\n",
       "Pressure                  0.001025  0.000768  0.073446  3  0.005426 -0.003375\n",
       "Speed                    -0.000206  0.000696  0.670472  3  0.003782 -0.004195\n",
       "WindDirection(Degrees)   -0.000311  0.001080  0.666522  3  0.005876 -0.006499"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = predictor.feature_importance(dev_df)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may check our website for more information and tutorials: https://auto.gluon.ai/. We also support automatically train models with text, image, and multimodal tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Erickson, Nick and Mueller, Jonas and Shirkov, Alexander and Zhang, Hang and Larroy, Pedro and Li, Mu and Smola, Alexander, AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data, 2020, https://arxiv.org/pdf/2003.06505.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
