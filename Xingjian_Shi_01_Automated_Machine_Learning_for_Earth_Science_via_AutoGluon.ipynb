{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning for Earth Science via AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author1 = {\"name\": \"Xingjian Shi\", \"affiliation\": \"Amazon Web Services\", \"email\": \"xjshi@amazon.com\", \"orcid\": \"\"}\n",
    "- Author2 = {\"name\": \"Wen-ming Ye\", \"affiliation\": \"Amazon Web Services\", \"email\": \"wye@amazon.com\", \"orcid\": \"\"}\n",
    "- Author3 = {\"name\": \"Nick Erickson\", \"affiliation\": \"Amazon Web Services\", \"email\": \"neerick@amazon.com\", \"orcid\": \"\"}\n",
    "- Author4 = {\"name\": \"Jonas Mueller\", \"affiliation\": \"Amazon Web Services\", \"email\": \"jonasmue@amazon.com\", \"orcid\": \"\"}\n",
    "- Author5 = {\"name\": \"Alexander Shirkov\", \"affiliation\": \"Amazon Web Services\", \"email\": \"ashyrkou@amazon.com\", \"orcid\": \"\"}\n",
    "- Author6 = {\"name\": \"Zhi Zhang\", \"affiliation\": \"Amazon Web Services\", \"email\": \"zhiz@amazon.com\", \"orcid\": \"\"}\n",
    "- Author7 = {\"name\": \"Mu Li\", \"affiliation\": \"Amazon Web Services\", \"email\": \"mli@amazon.com\", \"orcid\": \"\"}\n",
    "- Author8 = {\"name\": \"Alexander Smola\", \"affiliation\": \"Amazon Web Services\", \"email\": \"alex@smola.org\", \"orcid\": \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Purpose](#purpose)\n",
    "* [Forest Cover Type Classification](#forest-cover-type-classification)\n",
    "    * [Train Model with One Line](#train-model-with-one-line)\n",
    "    * [Evaluation and Prediction](#evaluation-and-prediction)\n",
    "    * [Load the Predictor](#load-the-predictor)\n",
    "    * [Feature Importance](#feature-importance)\n",
    "    * [Achieve Better Performance](#achieve-better-performance)\n",
    "* [Solar Radiation Prediction](#solar-radiation-predictions)\n",
    "* [More Information](#more-information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce [AutoGluon](https://github.com/awslabs/autogluon) to the Earth science community. AutoGluon is an automated machine learning toolkit that enables users to solve machine learning problems with a single line of code. Many earth science problems involve tabular-like datasets. With AutoGluon, you can feed in the **raw** data table and specify the `label` column. AutoGluon will deliver a model that has reasonable performance in a short period of time. In addition, with AutoGluon, you can also analyze the importance of each feature column with a single line of code. In the following, we illustrate how to use AutoGluon to build machine learning models for two Earth Science problems."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "We will install AutoGluon and fix the random seed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install \"autogluon[all]\"\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Cover Type Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first example, we will predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables. The dataset is downloaded from [Kaggle Forest Cover Type Prediction](https://www.kaggle.com/c/forest-cover-type-prediction). Study area of the dataset includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type. Let's first download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-13 09:40:12--  https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/forest-cover-type-prediction.zip\n",
      "Resolving deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)... 52.216.186.19\n",
      "Connecting to deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)|52.216.186.19|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26555059 (25M) [application/zip]\n",
      "Saving to: ‘forest-cover-type-prediction.zip’\n",
      "\n",
      "forest-cover-type-p 100%[===================>]  25.32M  93.3MB/s    in 0.3s    \n",
      "\n",
      "2021-04-13 09:40:12 (93.3 MB/s) - ‘forest-cover-type-prediction.zip’ saved [26555059/26555059]\n",
      "\n",
      "Archive:  forest-cover-type-prediction.zip\n",
      "  inflating: forest-cover-type-prediction/sampleSubmission.csv  \n",
      "  inflating: forest-cover-type-prediction/sampleSubmission.csv.zip  \n",
      "  inflating: forest-cover-type-prediction/test.csv  \n",
      "  inflating: forest-cover-type-prediction/test.csv.zip  \n",
      "  inflating: forest-cover-type-prediction/test3.csv  \n",
      "  inflating: forest-cover-type-prediction/train.csv  \n",
      "  inflating: forest-cover-type-prediction/train.csv.zip  \n"
     ]
    }
   ],
   "source": [
    "!wget https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/forest-cover-type-prediction.zip -O forest-cover-type-prediction.zip\n",
    "!unzip -o forest-cover-type-prediction.zip -d forest-cover-type-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load and visualize the dataset. We will split the dataset to 80% training and 20% development for the purpose of reporting the score on the development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('forest-cover-type-prediction/train.csv.zip')\n",
    "df = df.drop('Id', 1)\n",
    "train_df, dev_df = train_test_split(df, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visualizing the dataset, we can see that there are 54 feature columns and 1 label column called `\"Cover_Type\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>2132</td>\n",
       "      <td>252</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>940</td>\n",
       "      <td>188</td>\n",
       "      <td>249</td>\n",
       "      <td>198</td>\n",
       "      <td>1438</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>3270</td>\n",
       "      <td>95</td>\n",
       "      <td>25</td>\n",
       "      <td>134</td>\n",
       "      <td>30</td>\n",
       "      <td>2301</td>\n",
       "      <td>250</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10743</th>\n",
       "      <td>2387</td>\n",
       "      <td>200</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>592</td>\n",
       "      <td>214</td>\n",
       "      <td>252</td>\n",
       "      <td>170</td>\n",
       "      <td>577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12932</th>\n",
       "      <td>2286</td>\n",
       "      <td>307</td>\n",
       "      <td>30</td>\n",
       "      <td>270</td>\n",
       "      <td>197</td>\n",
       "      <td>713</td>\n",
       "      <td>124</td>\n",
       "      <td>206</td>\n",
       "      <td>214</td>\n",
       "      <td>1036</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10918</th>\n",
       "      <td>2672</td>\n",
       "      <td>221</td>\n",
       "      <td>30</td>\n",
       "      <td>134</td>\n",
       "      <td>89</td>\n",
       "      <td>2787</td>\n",
       "      <td>169</td>\n",
       "      <td>251</td>\n",
       "      <td>203</td>\n",
       "      <td>1206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "4138        2132     252     14                                30   \n",
       "8143        3270      95     25                               134   \n",
       "10743       2387     200     14                                 0   \n",
       "12932       2286     307     30                               270   \n",
       "10918       2672     221     30                               134   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "4138                                2                              940   \n",
       "8143                               30                             2301   \n",
       "10743                               0                              592   \n",
       "12932                             197                              713   \n",
       "10918                              89                             2787   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "4138             188             249            198   \n",
       "8143             250             194              0   \n",
       "10743            214             252            170   \n",
       "12932            124             206            214   \n",
       "10918            169             251            203   \n",
       "\n",
       "       Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "4138                                 1438  ...            0            0   \n",
       "8143                                  616  ...            0            0   \n",
       "10743                                 577  ...            0            0   \n",
       "12932                                1036  ...            0            0   \n",
       "10918                                1206  ...            0            0   \n",
       "\n",
       "       Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "4138             0            0            0            0            0   \n",
       "8143             0            0            0            0            0   \n",
       "10743            0            0            0            0            0   \n",
       "12932            0            0            0            0            0   \n",
       "10918            0            0            0            0            0   \n",
       "\n",
       "       Soil_Type39  Soil_Type40  Cover_Type  \n",
       "4138             0            0           4  \n",
       "8143             1            0           7  \n",
       "10743            0            0           6  \n",
       "12932            0            0           6  \n",
       "10918            0            0           3  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model with One Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a model in AutoGluon with a single line of code. We will just need to specify the label column before calling `.fit()`. Here, the label column is `Cover_Type`. AutoGluno will inference the problem type automatically. In our example, it can correctly figure out that it is a \"multiclass\" classification problem and output the model with the best accuracy. Internally, it will also figure out the feature type automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_ec2021_demo\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"ag_ec2021_demo/\"\n",
      "AutoGluon Version:  0.1.0\n",
      "Train Data Rows:    11340\n",
      "Train Data Columns: 54\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t7 unique label values:  [4, 7, 6, 3, 2, 5, 1]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "NumExpr defaulting to 8 threads.\n",
      "Train Data Class Count: 7\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23835.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.9 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['Soil_Type7', 'Soil_Type8', 'Soil_Type15']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 51 | ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 51 | ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.63 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10206, Val Rows: 1134\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t0.8589\t = Validation accuracy score\n",
      "\t25.5s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.858\t = Validation accuracy score\n",
      "\t28.98s\t = Training runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8201\t = Validation accuracy score\n",
      "\t0.05s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.828\t = Validation accuracy score\n",
      "\t0.05s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.858\t = Validation accuracy score\n",
      "\t1.33s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8616\t = Validation accuracy score\n",
      "\t1.72s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8668\t = Validation accuracy score\n",
      "\t1.02s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8624\t = Validation accuracy score\n",
      "\t1.12s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8721\t = Validation accuracy score\n",
      "\t4.6s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8713\t = Validation accuracy score\n",
      "\t3.73s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.858\t = Validation accuracy score\n",
      "\t12.72s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8748\t = Validation accuracy score\n",
      "\t32.89s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8827\t = Validation accuracy score\n",
      "\t13.82s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8968\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.61s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_ec2021_demo/\")\n"
     ]
    }
   ],
   "source": [
    "import autogluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label='Cover_Type', path='ag_ec2021_demo').fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the performance of each model with `predictor.leaderboard()`. Internally, AutoGluon trains multiple tabular models and computes a weighted ensemble at the last stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2   0.896825       0.369547  29.222437                0.000530           0.495989            2       True         14\n",
      "1         LightGBMLarge   0.882716       0.053217  13.815028                0.053217          13.815028            1       True         13\n",
      "2               XGBoost   0.874780       0.069986  32.888943                0.069986          32.888943            1       True         12\n",
      "3              LightGBM   0.872134       0.072509   4.604279                0.072509           4.604279            1       True          9\n",
      "4            LightGBMXT   0.871252       0.093603   3.734746                0.093603           3.734746            1       True         10\n",
      "5        ExtraTreesGini   0.866843       0.102842   1.020321                0.102842           1.020321            1       True          7\n",
      "6        ExtraTreesEntr   0.862434       0.102911   1.120916                0.102911           1.120916            1       True          8\n",
      "7      RandomForestEntr   0.861552       0.102714   1.724213                0.102714           1.724213            1       True          6\n",
      "8        NeuralNetMXNet   0.858907       0.075091  25.497201                0.075091          25.497201            1       True          1\n",
      "9              CatBoost   0.858025       0.007117  12.718287                0.007117          12.718287            1       True         11\n",
      "10     RandomForestGini   0.858025       0.102716   1.328101                0.102716           1.328101            1       True          5\n",
      "11      NeuralNetFastAI   0.858025       0.302020  28.977205                0.302020          28.977205            1       True          2\n",
      "12       KNeighborsDist   0.828042       0.102930   0.051896                0.102930           0.051896            1       True          4\n",
      "13       KNeighborsUnif   0.820106       0.104160   0.052982                0.104160           0.052982            1       True          3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.369547</td>\n",
       "      <td>29.222437</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.495989</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.053217</td>\n",
       "      <td>13.815028</td>\n",
       "      <td>0.053217</td>\n",
       "      <td>13.815028</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.874780</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>32.888943</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>32.888943</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.872134</td>\n",
       "      <td>0.072509</td>\n",
       "      <td>4.604279</td>\n",
       "      <td>0.072509</td>\n",
       "      <td>4.604279</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.871252</td>\n",
       "      <td>0.093603</td>\n",
       "      <td>3.734746</td>\n",
       "      <td>0.093603</td>\n",
       "      <td>3.734746</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.866843</td>\n",
       "      <td>0.102842</td>\n",
       "      <td>1.020321</td>\n",
       "      <td>0.102842</td>\n",
       "      <td>1.020321</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.862434</td>\n",
       "      <td>0.102911</td>\n",
       "      <td>1.120916</td>\n",
       "      <td>0.102911</td>\n",
       "      <td>1.120916</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.861552</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>1.724213</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>1.724213</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetMXNet</td>\n",
       "      <td>0.858907</td>\n",
       "      <td>0.075091</td>\n",
       "      <td>25.497201</td>\n",
       "      <td>0.075091</td>\n",
       "      <td>25.497201</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>12.718287</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>12.718287</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>0.102716</td>\n",
       "      <td>1.328101</td>\n",
       "      <td>0.102716</td>\n",
       "      <td>1.328101</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>0.302020</td>\n",
       "      <td>28.977205</td>\n",
       "      <td>0.302020</td>\n",
       "      <td>28.977205</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.828042</td>\n",
       "      <td>0.102930</td>\n",
       "      <td>0.051896</td>\n",
       "      <td>0.102930</td>\n",
       "      <td>0.051896</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.104160</td>\n",
       "      <td>0.052982</td>\n",
       "      <td>0.104160</td>\n",
       "      <td>0.052982</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2   0.896825       0.369547  29.222437   \n",
       "1         LightGBMLarge   0.882716       0.053217  13.815028   \n",
       "2               XGBoost   0.874780       0.069986  32.888943   \n",
       "3              LightGBM   0.872134       0.072509   4.604279   \n",
       "4            LightGBMXT   0.871252       0.093603   3.734746   \n",
       "5        ExtraTreesGini   0.866843       0.102842   1.020321   \n",
       "6        ExtraTreesEntr   0.862434       0.102911   1.120916   \n",
       "7      RandomForestEntr   0.861552       0.102714   1.724213   \n",
       "8        NeuralNetMXNet   0.858907       0.075091  25.497201   \n",
       "9              CatBoost   0.858025       0.007117  12.718287   \n",
       "10     RandomForestGini   0.858025       0.102716   1.328101   \n",
       "11      NeuralNetFastAI   0.858025       0.302020  28.977205   \n",
       "12       KNeighborsDist   0.828042       0.102930   0.051896   \n",
       "13       KNeighborsUnif   0.820106       0.104160   0.052982   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000530           0.495989            2       True   \n",
       "1                 0.053217          13.815028            1       True   \n",
       "2                 0.069986          32.888943            1       True   \n",
       "3                 0.072509           4.604279            1       True   \n",
       "4                 0.093603           3.734746            1       True   \n",
       "5                 0.102842           1.020321            1       True   \n",
       "6                 0.102911           1.120916            1       True   \n",
       "7                 0.102714           1.724213            1       True   \n",
       "8                 0.075091          25.497201            1       True   \n",
       "9                 0.007117          12.718287            1       True   \n",
       "10                0.102716           1.328101            1       True   \n",
       "11                0.302020          28.977205            1       True   \n",
       "12                0.102930           0.051896            1       True   \n",
       "13                0.104160           0.052982            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1          13  \n",
       "2          12  \n",
       "3           9  \n",
       "4          10  \n",
       "5           7  \n",
       "6           8  \n",
       "7           6  \n",
       "8           1  \n",
       "9          11  \n",
       "10          5  \n",
       "11          2  \n",
       "12          4  \n",
       "13          3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the model performance on the heldout predictor dataset by calling `.evaluate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive performance on given data: accuracy = 0.8772486772486773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8772486772486773"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the prediction, you may just use  `predictor.predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7777     7\n",
       "8689     5\n",
       "14825    1\n",
       "4925     6\n",
       "10184    7\n",
       "        ..\n",
       "11980    5\n",
       "7584     1\n",
       "3479     4\n",
       "8328     7\n",
       "9835     2\n",
       "Name: Cover_Type, Length: 3780, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictor.predict(dev_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problems, we can also use `.predict_proba` to get the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7777</th>\n",
       "      <td>0.075270</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>8.962022e-07</td>\n",
       "      <td>8.809570e-08</td>\n",
       "      <td>6.413592e-07</td>\n",
       "      <td>6.953858e-07</td>\n",
       "      <td>0.923438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>9.763250e-04</td>\n",
       "      <td>1.353729e-06</td>\n",
       "      <td>9.784312e-01</td>\n",
       "      <td>1.635405e-02</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>0.880177</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>2.141967e-06</td>\n",
       "      <td>1.022144e-06</td>\n",
       "      <td>2.351248e-05</td>\n",
       "      <td>8.070939e-06</td>\n",
       "      <td>0.113593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>4.139419e-01</td>\n",
       "      <td>1.343966e-03</td>\n",
       "      <td>2.404201e-06</td>\n",
       "      <td>5.842818e-01</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>3.632976e-06</td>\n",
       "      <td>8.345026e-07</td>\n",
       "      <td>1.156368e-05</td>\n",
       "      <td>3.524735e-06</td>\n",
       "      <td>0.991026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2             3             4             5  \\\n",
       "7777   0.075270  0.001290  8.962022e-07  8.809570e-08  6.413592e-07   \n",
       "8689   0.002839  0.001380  9.763250e-04  1.353729e-06  9.784312e-01   \n",
       "14825  0.880177  0.006195  2.141967e-06  1.022144e-06  2.351248e-05   \n",
       "4925   0.000004  0.000425  4.139419e-01  1.343966e-03  2.404201e-06   \n",
       "10184  0.008510  0.000444  3.632976e-06  8.345026e-07  1.156368e-05   \n",
       "\n",
       "                  6         7  \n",
       "7777   6.953858e-07  0.923438  \n",
       "8689   1.635405e-02  0.000018  \n",
       "14825  8.070939e-06  0.113593  \n",
       "4925   5.842818e-01  0.000001  \n",
       "10184  3.524735e-06  0.991026  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = predictor.predict_proba(dev_df)\n",
    "probs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a AutoGluon model is straight-forward. We can directly call `.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive performance on given data: accuracy = 0.8772486772486773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8772486772486773"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_loaded = TabularPredictor.load('ag_ec2021_demo')\n",
    "predictor_loaded.evaluate(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon offers a built-in method for calculating the relative importance of each feature based on [permutation-shuffling](https://scikit-learn.org/stable/modules/permutation_importance.html). In the following, we calculate the feature importance and print the top-10 important features. Here, `importance` means the importance score and the other values determine the statistical significance of the calculated score because we use random sampling in the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 54 features using 1000 rows with 3 shuffle sets...\n",
      "\t159.69s\t= Expected runtime (53.23s per shuffle set)\n",
      "\t19.53s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>3</td>\n",
       "      <td>0.551649</td>\n",
       "      <td>0.459017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>3</td>\n",
       "      <td>0.197517</td>\n",
       "      <td>0.092483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.109333</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>3</td>\n",
       "      <td>0.170065</td>\n",
       "      <td>0.048601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.070333</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>3</td>\n",
       "      <td>0.122327</td>\n",
       "      <td>0.018340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>-0.006660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039172</td>\n",
       "      <td>-0.012505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.029818</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037746</td>\n",
       "      <td>-0.016413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>-0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type10</th>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance    stddev   p_value  n  \\\n",
       "Elevation                             0.505333  0.008083  0.000043  3   \n",
       "Horizontal_Distance_To_Roadways       0.145000  0.009165  0.000665  3   \n",
       "Horizontal_Distance_To_Fire_Points    0.109333  0.010599  0.001559  3   \n",
       "Horizontal_Distance_To_Hydrology      0.070333  0.009074  0.002751  3   \n",
       "Hillshade_Noon                        0.014000  0.003606  0.010701  3   \n",
       "Vertical_Distance_To_Hydrology        0.013333  0.004509  0.018037  3   \n",
       "Aspect                                0.012667  0.002082  0.004441  3   \n",
       "Wilderness_Area1                      0.010667  0.004726  0.029818  3   \n",
       "Wilderness_Area4                      0.008333  0.002309  0.012329  3   \n",
       "Soil_Type10                           0.003667  0.000577  0.004082  3   \n",
       "\n",
       "                                    p99_high   p99_low  \n",
       "Elevation                           0.551649  0.459017  \n",
       "Horizontal_Distance_To_Roadways     0.197517  0.092483  \n",
       "Horizontal_Distance_To_Fire_Points  0.170065  0.048601  \n",
       "Horizontal_Distance_To_Hydrology    0.122327  0.018340  \n",
       "Hillshade_Noon                      0.034660 -0.006660  \n",
       "Vertical_Distance_To_Hydrology      0.039172 -0.012505  \n",
       "Aspect                              0.024595  0.000738  \n",
       "Wilderness_Area1                    0.037746 -0.016413  \n",
       "Wilderness_Area4                    0.021566 -0.004900  \n",
       "Soil_Type10                         0.006975  0.000358  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = predictor.feature_importance(dev_df)\n",
    "importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achieve Better Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default behavior of AutoGluon is to compute a weighted ensemble of a diverse set of models. Usually, you can achieve better performance via stack ensembling. To achieve better performance based on automated stack ensembling, you can specify `presets=\"best_quality\"` when calling `.fit()` in AutoGluon. For more details, you can also checkout our provided script. The detailed architecture is described in [1] and we also provide the following figure so you can know the general architecture.\n",
    "\n",
    "<img src=\"https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/stacking.png\" alt=\"screenshot\" style=\"width: 500px;\"/>\n",
    "\n",
    "With `.fit(train_df, presets=\"best_quality\")`, we are able to achieve 82/1692 in the competition.\n",
    "\n",
    "<img src=\"https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/forest_cover_type.png\" alt=\"screenshot\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Radiation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second example, we will train model to predict the solar radiation. The orignal dataset is available in [Kaggle Solar Radiation Prediction](https://www.kaggle.com/dronio/SolarEnergy). The dataset contains such columns as: \"wind direction\", \"wind speed\", \"humidity\" and \"temperature\". The response parameter that is to be predicted is: \"Solar_radiation\". It contains measurements for the past 4 months and you have to predict the level of solar radiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-13 09:42:57--  https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/SolarPrediction.csv.zip\n",
      "Resolving deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)... 52.216.241.36\n",
      "Connecting to deep-earth.s3.amazonaws.com (deep-earth.s3.amazonaws.com)|52.216.241.36|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 523425 (511K) [application/zip]\n",
      "Saving to: ‘SolarPrediction.csv.zip’\n",
      "\n",
      "SolarPrediction.csv 100%[===================>] 511.16K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2021-04-13 09:42:57 (40.3 MB/s) - ‘SolarPrediction.csv.zip’ saved [523425/523425]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://deep-earth.s3.amazonaws.com/datasets/earthcube2021_demo/SolarPrediction.csv.zip -O SolarPrediction.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('SolarPrediction.csv.zip')\n",
    "train_df, dev_df = train_test_split(df, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIXTime</th>\n",
       "      <th>Data</th>\n",
       "      <th>Time</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindDirection(Degrees)</th>\n",
       "      <th>Speed</th>\n",
       "      <th>TimeSunRise</th>\n",
       "      <th>TimeSunSet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>1474412104</td>\n",
       "      <td>9/20/2016 12:00:00 AM</td>\n",
       "      <td>12:55:04</td>\n",
       "      <td>1039.15</td>\n",
       "      <td>65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>57</td>\n",
       "      <td>2.26</td>\n",
       "      <td>5.62</td>\n",
       "      <td>06:11:00</td>\n",
       "      <td>18:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12230</th>\n",
       "      <td>1476543319</td>\n",
       "      <td>10/15/2016 12:00:00 AM</td>\n",
       "      <td>04:55:19</td>\n",
       "      <td>1.21</td>\n",
       "      <td>51</td>\n",
       "      <td>30.46</td>\n",
       "      <td>23</td>\n",
       "      <td>181.58</td>\n",
       "      <td>6.75</td>\n",
       "      <td>06:17:00</td>\n",
       "      <td>17:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11706</th>\n",
       "      <td>1476704422</td>\n",
       "      <td>10/17/2016 12:00:00 AM</td>\n",
       "      <td>01:40:22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>50</td>\n",
       "      <td>30.47</td>\n",
       "      <td>39</td>\n",
       "      <td>142.56</td>\n",
       "      <td>10.12</td>\n",
       "      <td>06:18:00</td>\n",
       "      <td>17:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924</th>\n",
       "      <td>1476330025</td>\n",
       "      <td>10/12/2016 12:00:00 AM</td>\n",
       "      <td>17:40:25</td>\n",
       "      <td>28.35</td>\n",
       "      <td>59</td>\n",
       "      <td>30.45</td>\n",
       "      <td>42</td>\n",
       "      <td>167.42</td>\n",
       "      <td>4.50</td>\n",
       "      <td>06:16:00</td>\n",
       "      <td>18:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27507</th>\n",
       "      <td>1482367563</td>\n",
       "      <td>12/21/2016 12:00:00 AM</td>\n",
       "      <td>14:46:03</td>\n",
       "      <td>637.93</td>\n",
       "      <td>57</td>\n",
       "      <td>30.39</td>\n",
       "      <td>74</td>\n",
       "      <td>40.94</td>\n",
       "      <td>4.50</td>\n",
       "      <td>06:53:00</td>\n",
       "      <td>17:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>1474457405</td>\n",
       "      <td>9/21/2016 12:00:00 AM</td>\n",
       "      <td>01:30:05</td>\n",
       "      <td>1.21</td>\n",
       "      <td>45</td>\n",
       "      <td>30.39</td>\n",
       "      <td>73</td>\n",
       "      <td>159.07</td>\n",
       "      <td>3.37</td>\n",
       "      <td>06:11:00</td>\n",
       "      <td>18:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32227</th>\n",
       "      <td>1480723808</td>\n",
       "      <td>12/2/2016 12:00:00 AM</td>\n",
       "      <td>14:10:08</td>\n",
       "      <td>177.19</td>\n",
       "      <td>45</td>\n",
       "      <td>30.34</td>\n",
       "      <td>93</td>\n",
       "      <td>134.78</td>\n",
       "      <td>11.25</td>\n",
       "      <td>06:42:00</td>\n",
       "      <td>17:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12705</th>\n",
       "      <td>1476396922</td>\n",
       "      <td>10/13/2016 12:00:00 AM</td>\n",
       "      <td>12:15:22</td>\n",
       "      <td>1008.08</td>\n",
       "      <td>65</td>\n",
       "      <td>30.46</td>\n",
       "      <td>46</td>\n",
       "      <td>71.24</td>\n",
       "      <td>5.62</td>\n",
       "      <td>06:17:00</td>\n",
       "      <td>18:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>1475697322</td>\n",
       "      <td>10/5/2016 12:00:00 AM</td>\n",
       "      <td>09:55:22</td>\n",
       "      <td>292.44</td>\n",
       "      <td>55</td>\n",
       "      <td>30.47</td>\n",
       "      <td>101</td>\n",
       "      <td>18.70</td>\n",
       "      <td>7.87</td>\n",
       "      <td>06:14:00</td>\n",
       "      <td>18:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23615</th>\n",
       "      <td>1478267417</td>\n",
       "      <td>11/4/2016 12:00:00 AM</td>\n",
       "      <td>03:50:17</td>\n",
       "      <td>1.18</td>\n",
       "      <td>44</td>\n",
       "      <td>30.42</td>\n",
       "      <td>38</td>\n",
       "      <td>176.34</td>\n",
       "      <td>7.87</td>\n",
       "      <td>06:25:00</td>\n",
       "      <td>17:47:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UNIXTime                    Data      Time  Radiation  Temperature  \\\n",
       "2664   1474412104   9/20/2016 12:00:00 AM  12:55:04    1039.15           65   \n",
       "12230  1476543319  10/15/2016 12:00:00 AM  04:55:19       1.21           51   \n",
       "11706  1476704422  10/17/2016 12:00:00 AM  01:40:22       1.22           50   \n",
       "12924  1476330025  10/12/2016 12:00:00 AM  17:40:25      28.35           59   \n",
       "27507  1482367563  12/21/2016 12:00:00 AM  14:46:03     637.93           57   \n",
       "2516   1474457405   9/21/2016 12:00:00 AM  01:30:05       1.21           45   \n",
       "32227  1480723808   12/2/2016 12:00:00 AM  14:10:08     177.19           45   \n",
       "12705  1476396922  10/13/2016 12:00:00 AM  12:15:22    1008.08           65   \n",
       "14992  1475697322   10/5/2016 12:00:00 AM  09:55:22     292.44           55   \n",
       "23615  1478267417   11/4/2016 12:00:00 AM  03:50:17       1.18           44   \n",
       "\n",
       "       Pressure  Humidity  WindDirection(Degrees)  Speed TimeSunRise  \\\n",
       "2664      30.40        57                    2.26   5.62    06:11:00   \n",
       "12230     30.46        23                  181.58   6.75    06:17:00   \n",
       "11706     30.47        39                  142.56  10.12    06:18:00   \n",
       "12924     30.45        42                  167.42   4.50    06:16:00   \n",
       "27507     30.39        74                   40.94   4.50    06:53:00   \n",
       "2516      30.39        73                  159.07   3.37    06:11:00   \n",
       "32227     30.34        93                  134.78  11.25    06:42:00   \n",
       "12705     30.46        46                   71.24   5.62    06:17:00   \n",
       "14992     30.47       101                   18.70   7.87    06:14:00   \n",
       "23615     30.42        38                  176.34   7.87    06:25:00   \n",
       "\n",
       "      TimeSunSet  \n",
       "2664    18:21:00  \n",
       "12230   17:59:00  \n",
       "11706   17:58:00  \n",
       "12924   18:02:00  \n",
       "27507   17:49:00  \n",
       "2516    18:20:00  \n",
       "32227   17:42:00  \n",
       "12705   18:01:00  \n",
       "14992   18:08:00  \n",
       "23615   17:47:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in our previos example, we can directly train a predictor with a single `.fit()` call. The difference is that AutoGluon can automatically determine that it is a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_ec2021_demo2\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"ag_ec2021_demo2/\"\n",
      "AutoGluon Version:  0.1.0\n",
      "Train Data Rows:    24514\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1601.26, 1.11, 206.52072, 315.54334)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20110.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.88 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 3 | ['Pressure', 'WindDirection(Degrees)', 'Speed']\n",
      "\t\t('int', [])                        : 3 | ['UNIXTime', 'Temperature', 'Humidity']\n",
      "\t\t('object', ['datetime_as_object']) : 4 | ['Data', 'Time', 'TimeSunRise', 'TimeSunSet']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['Pressure', 'WindDirection(Degrees)', 'Speed']\n",
      "\t\t('int', [])                  : 3 | ['UNIXTime', 'Temperature', 'Humidity']\n",
      "\t\t('int', ['datetime_as_int']) : 4 | ['Data', 'Time', 'TimeSunRise', 'TimeSunSet']\n",
      "\t17.6s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 17.64s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 22062, Val Rows: 2452\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t0.9433\t = Validation r2 score\n",
      "\t7.01s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t0.9463\t = Validation r2 score\n",
      "\t3.3s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.9501\t = Validation r2 score\n",
      "\t0.03s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.9531\t = Validation r2 score\n",
      "\t0.03s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9438\t = Validation r2 score\n",
      "\t2.29s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's l2: 5825\ttrain_set's r2: 0.941343\tvalid_set's l2: 6881.24\tvalid_set's r2: 0.932405\n",
      "[2000]\ttrain_set's l2: 4818.35\ttrain_set's r2: 0.951483\tvalid_set's l2: 6360.95\tvalid_set's r2: 0.937497\n",
      "[3000]\ttrain_set's l2: 4202.38\ttrain_set's r2: 0.957684\tvalid_set's l2: 6212.24\tvalid_set's r2: 0.938993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9393\t = Validation r2 score\n",
      "\t8.77s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.942\t = Validation r2 score\n",
      "\t4.82s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9444\t = Validation r2 score\n",
      "\t4.15s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t0.9372\t = Validation r2 score\n",
      "\t107.26s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/callbacks/tracker.py:50: UserWarning: <class 'autogluon.tabular.models.fastainn.callbacks.EarlyStoppingCallbackWithTimeLimit'> conditioned on metric `r2` which is not available. Available metrics are: train_loss, valid_loss, r2_score\n",
      "  warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {\", \".join(map(str, self.learn.recorder.names[1:-1]))}')\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/callbacks/tracker.py:50: UserWarning: <class 'autogluon.tabular.models.fastainn.callbacks.SaveModelCallback'> conditioned on metric `r2` which is not available. Available metrics are: train_loss, valid_loss, r2_score\n",
      "  warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {\", \".join(map(str, self.learn.recorder.names[1:-1]))}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\t[Errno 2] No such file or directory: '/tmp/tmpiiz9m03_/models/NeuralNetFastAI.pth'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 911, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 883, in _train_single\n",
      "    model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 405, in fit\n",
      "    self._fit(**kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 244, in _fit\n",
      "    model.load(self.name)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/fastai/basic_train.py\", line 269, in load\n",
      "    state = torch.load(source, map_location=device)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/torch/serialization.py\", line 581, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpiiz9m03_/models/NeuralNetFastAI.pth'\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9445\t = Validation r2 score\n",
      "\t2.29s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9548\t = Validation r2 score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 231.15s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_ec2021_demo2/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='Radiation', eval_metric='r2', path='ag_ec2021_demo2').fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate on the development set with the same approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive performance on given data: r2 = 0.9544595815213469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9544595815213469"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may check our website for more information and tutorials: https://auto.gluon.ai/. We also support automatically train models with text, image, and multimodal tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Erickson, Nick and Mueller, Jonas and Shirkov, Alexander and Zhang, Hang and Larroy, Pedro and Li, Mu and Smola, Alexander, AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data, 2020, https://arxiv.org/pdf/2003.06505.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}